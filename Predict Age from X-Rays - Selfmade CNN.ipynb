{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicting Age from X-Rays with Deep Learning\nAfter finishing the great kaggle course [Deep Learning](https://www.kaggle.com/learn/deep-learning), I'm trying to get some practice with this dataset.\n## Setup"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preview the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/boneage-training-dataset.csv\")\ntrain_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(os.listdir(\"../input/boneage-training-dataset/boneage-training-dataset\"))\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfor img_id, boneage, male in train_df[['id','boneage','male']].sample(3).values:\n    img_name = str(img_id) + '.png'\n    img = mpimg.imread(\"../input/boneage-training-dataset/boneage-training-dataset/\"+img_name)\n    plt.imshow(img)\n    plt.title('Image: {} Boneage: {} Male: {}'.format(img_name, boneage, male))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Function for preparing images taken from the [deep learning course of DanB](https://www.kaggle.com/dansbecker/tensorflow-programming)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom tensorflow.python.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.python.keras.preprocessing.image import load_img, img_to_array\n\ndef read_and_prep_images(img_paths, img_height, img_width, color_mode=\"grayscale\"):\n    imgs = [load_img(img_path, target_size=(img_height, img_width), color_mode=color_mode) for img_path in img_paths]\n    img_array = np.array([img_to_array(img) for img in imgs])\n    #output = preprocess_input(img_array)\n    return(img_array)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating the Model\nI want to do regression instead of classification, so I have to do some changes compared to the deep learning method."},{"metadata":{},"cell_type":"markdown","source":"### Initial model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D\n\n# quadratic approach\nquadratic = True\nimage_size = 128\n\n# some kind of ratio if not quadratic approach\nimg_rows = image_size if quadratic else 144 \nimg_cols = image_size if quadratic else 114\n\ninitial_model = Sequential()\n\n# Input Layer\ninitial_model.add(Conv2D(12, kernel_size=(4,4), activation='relu', input_shape=(img_rows, img_cols, 1)))\n\n\n# Convulotional Layers\ninitial_model.add(Conv2D(20, kernel_size=(4,4), activation='relu'))\ninitial_model.add(Conv2D(20, kernel_size=(3,3), activation='relu'))\n\n# Flattening\ninitial_model.add(Flatten())\n\n# Dense Layer\ninitial_model.add(Dense(100))\ninitial_model.add(Dense(1))\n\ninitial_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### New model\nNot so new anymore... but had the best results so far."},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout\n\nboner_model = Sequential()\n\n# Input Layer\nboner_model.add(Conv2D(16, kernel_size=(7,7), strides=(2,2), activation='relu', input_shape=(img_rows, img_cols, 3)))\nboner_model.add(Dropout(0.25))\n\n# Convulotional Layers\nboner_model.add(Conv2D(32, kernel_size=(5,5), strides=(2,2), activation='relu'))\nboner_model.add(Dropout(0.25))\nboner_model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n#boner_model.add(Dropout(0.25))\nboner_model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\nboner_model.add(Dropout(0.25))\n\n# Flattening\nboner_model.add(Flatten())\n\n# Dense Layer\nboner_model.add(Dense(256, activation='relu'))\n#boner_model.add(Dropout(0.25))\nboner_model.add(Dense(1))\n\nboner_model.compile(loss='mean_squared_error', optimizer='adam')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thanks to Vijayabhaskar I was able to combine augmentation with sequential loading data into memry. See his [blog post](https://medium.com/@vijayabhaskar96/tutorial-on-keras-imagedatagenerator-with-flow-from-dataframe-8bd5776e45c1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\n\ntrain_df['imagepath'] = [f'{pid}.png' for pid in train_df.id]\n#Lazy way of creating training and test set.\ntrain = train_df.head(10000)\ntest = train_df.tail(2600)\n\n\ndatagen=ImageDataGenerator(rescale=1./255, rotation_range=20, zoom_range=0.15,\n                           width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n                           horizontal_flip=True, fill_mode=\"nearest\")\ntrain_generator=datagen.flow_from_dataframe(dataframe=train, \n                                            directory=\"../input/boneage-training-dataset/boneage-training-dataset/\", \n                                            x_col=\"imagepath\", \n                                            y_col=\"boneage\", \n                                            class_mode=\"other\", \n                                            target_size=(img_rows,img_cols), \n                                            batch_size=32)\n\nvalid_generator=datagen.flow_from_dataframe(dataframe=test, \n                                            directory=\"../input/boneage-training-dataset/boneage-training-dataset/\", \n                                            x_col=\"imagepath\", \n                                            y_col=\"boneage\", \n                                            class_mode=\"other\", \n                                            target_size=(img_rows,img_cols), \n                                            batch_size=32)\n\nSTEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\nhistory = boner_model.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n# Plot training & validation loss values\nf, ax = plt.subplots(1,1, figsize=(15,10))\nax.plot(history.history['loss'])\nax.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nax.grid(color='grey')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing the Filters of my CNN\nBased on this great blog post https://towardsdatascience.com/how-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030 I want to see what patterns the filters of my CNN are looking for.\n\nRan into several problems. My model is TF/Keras and the blogs code is in Torch/fastai. Came up with a really messed up way to run the code but the image still look like blurred random images. Trying to figure out how to move on.\n\nI could recreate the model in Torch and try it with the code as found on the blog. Or I could try to dig deeper.\n\nLets see what I will do next time... \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import models\nimport torch\nimport cv2\n\nlayer_level = 5\nfilter = 3\n\ndef mygawd(layer_level, filter):\n    opt_steps = 100\n    upscaling_steps = 12\n    upscaling_factor = 1.2\n    blur = 5\n    sz = 56\n    \n    img = np.uint8(np.random.uniform(150, 180, (sz, sz, 3)))/255\n\n\n    layer_outputs = [layer.output for layer in boner_model.layers] # Extracts the outputs of the top layers\n    activation_model = models.Model(inputs=boner_model.input, outputs=layer_outputs[layer_level]) # Creates a model that will return these outputs, given the model input\n    activation_model.trainable = False\n    \n    img_var = torch.tensor(np.array([img]),requires_grad=True)\n    #print(f'img_var.mean() before: {img_var.mean()}')\n    for _ in range(upscaling_steps):  # scale the image up upscaling_steps times\n        optimizer = torch.optim.Adam([img_var], lr=0.1, weight_decay=1e-6)\n        #print('peng')\n        for n in range(opt_steps):  # optimize pixel values for opt_steps times\n            #optimizer.zero_grad()\n            # Ugly way to get the data out of the variable and make it posssible to send it to the model\n            temp = img_var[:,:,:,:].detach().numpy()\n            feature_map = activation_model.predict(cv2.resize(temp.reshape((sz,sz,3)), (128, 128)).reshape((1,128,128,3)))\n            activation =torch.tensor(feature_map[0,:,:,filter],requires_grad=True)\n            loss = -activation.mean()\n            #print(f'loss: {loss}')\n            loss.backward()\n            # Couldn't figure out another way to update the pixels of img_var... probably won't work... sigh\n            img_var.backward(gradient=torch.ones([1, sz, sz, 3], dtype=torch.float64) * activation.grad.mean())\n            optimizer.step()\n        sz = int(upscaling_factor * sz)  # calculate new image size\n        img = img_var.data.cpu().numpy()[0]\n        img = cv2.resize(img, (sz, sz), interpolation = cv2.INTER_CUBIC)  # scale image up\n        if blur is not None: img = cv2.blur(img,(blur,blur)) # blur image to reduce high frequency patterns\n        img_var = torch.tensor(np.array([img]),requires_grad=True)\n    #print(f'img_var.mean() after: {img_var.mean()}')\n    #print(f'activation.shape: {activation.shape}')\n    #fig, ax = plt.subplots()\n    #ax.imshow((img_var[0,:,:,].detach().numpy()* 255).astype(np.uint8))\n    #ax.set_title(f'Layer {layer_level} Filter {filter}')\n    #plt.axis('off')\n    return (img_var[0,:,:,].detach().numpy()* 255).astype(np.uint8)\n\nfor i, filter in enumerate(range(100,110)):\n    # Ad new row if row is full\n    if i%5 == 0:\n        fig, axes = plt.subplots(1,5, figsize=(20,5))\n    filter_img = mygawd(layer_level, filter)\n    axes[i%5].imshow(filter_img)\n    at = axes[i%5].set_title(f'Layer {layer_level} Filter {filter}')\n    at = axes[i%5].set_xticks([])\n    at = axes[i%5].set_yticks([])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}